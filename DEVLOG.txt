****

My goal now is to capture video with OpenCV but show it with Qt...
Capture starts now. No camera selection yet (default camera) - that's for later.

Now: how to display? I should be able to display one of the several stages of
the video filters and draw stuff on top. Custom widget seems apropriate.

Or may be: QGr.View with all them layers like?

The structure should be something like:
- video is a root item which reacts on resizing
    - under the root are pixmap items and overlay graphics
- HUD is a different root item which reacts on resizing differently
    - under the HUD are HUD graphics


To display an image I need to convert it from OpenCV's Mat to Qt's QPixmap (or similar).
The simplest is if I convert Mat to some well known format first.

continue modularization:

* * *

[x] Detect and show eyes
    ( ) Better: given two sets of potential eyes find best pair:
        ( ) pair scores: size difference, y difference
        --- works for now, but eats a lot of CPU.
[ ] Transform / crop the face to normalize the eyes distance / orientation
    - find the rotated square around the face (from the eyes down then grow / shift)
    - find the affine matrix to get it into 100x100
    - warpAffine(... )
[ ] Move view controls to the dock
[ ] Add min face size control to the dock
[ ] Display current frame sizes and FPS somewhere
[ ] Offline face learner
[ ] Online face matcher in a separate thread

Detect faces and show them.

Should this use verilook? It gives us eye positions...

CV can do that as well. What I need is:

For robot control don't need eyes or matching - just make sure it runs fast.
But need eyes for preprocessing / matching.

Now: make faster, need scaled down version.
Now: draw the rectangle(s) over video.
Stretching the contrast helped really well.
Run left/right eye cascades on the two regions (but cut them out of the original grey).

* * *

a sidetrack: make the mirror easier to readjust for different purposes.
[x] drop movie support
[x] (compile time) configurable tick() handler
    - should really be a class that has an incoming frame slot and can connect to the canvas
[ ] tick() handler dependent controls
    [ ] let the filter set up controls it wants

football players tracking:

1. background learning
    - simplest: a movie of the empty field
        - not always possible
        - will change with time (sun, clouds)
    - statistical:
        - collect histograms of image tiles for some time
        - for each tile: find similar histograms that occur the oftenest, assume that to be the background
            - this requires automatic classification of the histograms
    - dynamic
        - start with initial background (e.g. all green, or a single shot of empty field or statistically collected)
        - after blob detection use remainder of the image to update the tile histograms
            - see codebooks (p. 278)
2. detect areas different from the background
    - given tile histogram generate backprojection
    - combine all tile's backprojections to a single probability image
    - threshold / morphological operations
3. find blob shapes
    - contours of "white" areas
4. calculate histograms inside the blobs
5. classify the blobs based on area / histogram
6. blob location
    - use mid-lowest point as blob coordinates (in case of a single player corresponds to feet at the ground level)
    - rectify / unproject based on 4 points

Extra considerations:
- cvPyrMeanShiftFiltering is slow but simplifies the image a lot. helps to
  keep the histograms distinct. when to use it? may be to generate the inital
histograms.
- the furthest background (in the test video) can be problematic, but as long
  as their uniforms are bright and in contrast with the background it's ok
- it would be clever to perspective-correct image when scaling down: minimize
  amount of processing for the foreground and loss of detail for the
background.
    - TODO find which opencv geometric transformation functions does it, there
      is one that can do both in one go.

Learning the field:
1. learning field color histogram
1.1. assume the field is green with white: have a default field histogram ready or let user rubber band a small portion to start it off
    (best a portion including light, shadow on both grass and white markings).
1.2. backproject the histogram onto the frame, collect pixels above sertain threshold into a field mask, calculate histogram of these pixels - this will be the new histogram
1.3. repeat increasing threshold until certain level of confidence / accuracy. Now we have the current field histogram
2. learning field position inside the frame
2.1. backproject field histogram onto current frame
2.2. do a morphological operation to fix small holes
2.3. select the largest contour and find its convex hull, around 6 corners. That's the field area
3. field shape fitting
3.1. divide the field into several roughly defined areas
3.2. search for features (corners of white marking) inside each area
3.3. each found corner corresponds to exact football (X,Y) -> use found corners to find tracking area, perspective correction and lens undistortion parameters


* * *

A flexible way to do video exploration:

[x] a VisionFilter registers a number of cv::Mat's in a dictionary
[x] it uses them directly because they are also its fields
[x] default 'incomingFrame()' does:
    1. store the incoming in the 'input' slot
    2. calls virtual filter() function
    3. displays selected slot

* * *

stagewise refactoring towards modular filter support:

[x] split current filter implementation into two classes - base filter class and football tracker
[x] split the face tracker part as well - including its gui
[x] remove the layer menu items
[x] remove the toolbar
[x] digit keys to stage selector: add key event handler to main window and react on digits there

* * *

[x] load the field-sample and take its histogram. this will be the starting field histogram
[-] backproject, threshold, update histogram (working field histogram)
[x] backproject, threshold, close, find blobs, take the largest, take its convex hull, this will be the field
    [ ] if several contours - keep the largest
    [ ] ROI - hull's bounding rect
    [ ] mask - draw hull as white

[ ] bg/fg segmentation: once we have an ROI and a mask do background detection, then inverse threshold and morph dilate
[ ] find all countours and show them as little blobular shapes

* * *

(Tue Mar 22)

switching to verilook again.

made a wizard for Mirror::VisionFilter subclasses.

Verilook SDK is in ~/SDK/VeriLook_3_2_Standard_SDK/VL32/...
Let's try adding the right things to include / library search paths...

... roll back
Verilook include / lib on a mac seem to be in /Library/Verilook
So...

- Let's see if we can make it include / initialize verilook stuff.

- Now that it was forced to recompile/relink it complains that I don't have the right dylibs:
  "warning: in /Library/Verilook/lib/libNLExtractor.dylib, missing required architecture x86_64 in file"
- I should probably reinstall verilook sdk. how?
  - just reinstalling from .pkg didn't work - installs 32bit versions
  - see if I have other versions of the SDK downloaded... no
  - downloaded SDK 3.3 (there is also 4.0, will download that as well, just to test)
  - apparently SDK 3.3 installs dynlibs into /Library/Frameworks/Neurotechnology/
    - includes aren't installed at all, but we can find them...
  - libs are universal PPC/i386(32bit). foketifok...
  - let's try 4.0
    - universal PPC/i386/x86_64
    - links ok, can't get no license...
      - yes we can (activation wasn't running)
  - oops, need to refer to the correct includes again...
  - ok, license obtain/release works. let's see if we can detect faces in
    video coming from opencv...
    - yes. now the eyes (but don't need eyes always, have a boolean flag).
    - eyes work as well.
  - now to recognition: I need some sort of coroutines that do the following:
    - loading the database in the background
    - matching the the face against the database
  - don't have to be full-fledged coroutines, just idle handler with state
    - actually, loading the database is slow, not sure why is that...

face recognition:
[ ] switch on and offable recognition
    [x] logic for locking/disabling eye detection ?
    [x] see how slow it is (making the template)
        it is slow indeed...
    [x] an idle handler for recognition: if there is a template to match
        match certain number of templates each idle

[ ] progress bars:
    [ ] database loading
    [ ] matching
[ ] best match display: show the best match so far as a small image somewhere


From program log:
> "Matching template created in 397 ms"
> "Reached the end of the database in 64 ms (8093.75 face/sec)"

have to move matching to a separate thread.

before matching have to extract a template and that requires an extractor
object, have to share it.

* * *

New class wizard...

followed http://doc.qt.nokia.com/qtcreator-snapshot/creator-project-wizards.html
the wizard is in ~/.config/Nokia/qtcreator/templates/wizards/NewMirrorClass/

* * *

opencv
~~~~~~

on osx
======

I have built the 2.2.0 version using cmake.

should probably make it build from qt creator (it supports cmake projects)

on windows
==========

Building OpenCV on windows.

Had really hard time recalling what's my build environment on windows.
Eventually...:

1. Menu Start > MinGW > MinGW Shell
2. cd /y/src/Mirror/Shoulders/opencv-build-win
3. cmake ../OpenCV-2.2.0 -G "MSYS Makefiles"
4. make

missing videoInput... should I find it somewhere?
https://github.com/ofTheo/videoInput

copied and renamed the library compiled with DevCpp (didn't bother to
build my own) to 3rdparty/lib/libvideoInput.a

that seems to have helped.

next it can't build ffmpeg part. looks for built libraries in some place.
I should have disabled ffmpeg.

that's:
cmake WITH_FFMPEG=0 ../OpenCV-2.2.0

still very slow everything. Is this because I'm at mac disk from windows?
indeed that was it.

after having copied the OpenCV-2.2.0 to the Parallels mounted windows disk it
contained a bunch of files with names starting with "._" and make was breaking
on them. had to:

find . -name "._*" | xargs rm

This time building OpenCV inside the source directory (since it's copied
anyway). Will break on videoInput and ffmpeg - will think how to deal with
that later. 

cp ../videoInput/compiledLib/compiledByDevCpp/videoInputLib.a \
3rdparty/lib/libvideoInput.a

WITH_FFMPEG=0 doesn't help

* * *

Gave up on opencv on windows for now.

* * *

Continue with football++

After all the fiddling about with Mirror / OpenCV have to restore the build environment and build the OpenCV a new.
Took a while. I've changed the build directory, so had to symlink the Resources into there for football tracker to find
field "template".

[x] zoom in/out slider
    added by the tracker to ... well, somewhere
[x] field quad editor
    added by the tracker - a filter on canvas's mouse events...
[ ] new processing phase: perspective corrected
[ ] track in perspective corrected field
[ ] detect blobs
[ ] for each blob
    [ ] find anchor position (mid-low point of the bounding rect)
    [ ] find area
    [ ] calc histogram of may be 5 main colors
    [ ] be ready to send the list of blobs in whatever format is expected from us
