****

My goal now is to capture video with OpenCV but show it with Qt...
Capture starts now. No camera selection yet (default camera) - that's for later.

Now: how to display? I should be able to display one of the several stages of the video filters and draw stuff on top. Custom widget seems apropriate.

Or may be: QGr.View with all them layers like?

The structure should be something like:
- video is a root item which reacts on resizing
    - under the root are pixmap items and overlay graphics
- HUD is a different root item which reacts on resizing differently
    - under the HUD are HUD graphics


To display an image I need to convert it from OpenCV's Mat to Qt's QPixmap (or similar).
The simplest is if I convert Mat to some well known format first.

continue modularization:

* * *

[x] Detect and show eyes
    ( ) Better: given two sets of potential eyes find best pair:
        ( ) pair scores: size difference, y difference
        --- works for now, but eats a lot of CPU.
[ ] Transform / crop the face to normalize the eyes distance / orientation
    - find the rotated square around the face (from the eyes down then grow / shift)
    - find the affine matrix to get it into 100x100
    - warpAffine(... )
[ ] Move view controls to the dock
[ ] Add min face size control to the dock
[ ] Display current frame sizes and FPS somewhere
[ ] Offline face learner
[ ] Online face matcher in a separate thread

Detect faces and show them.

Should this use verilook? It gives us eye positions...

CV can do that as well. What I need is:

For robot control don't need eyes or matching - just make sure it runs fast.
But need eyes for preprocessing / matching.

Now: make faster, need scaled down version.
Now: draw the rectangle(s) over video.
Stretching the contrast helped really well.
Run left/right eye cascades on the two regions (but cut them out of the original grey).

* * *

a sidetrack: make the mirror easier to readjust for different purposes.
[x] drop movie support
[x] (compile time) configurable tick() handler
    - should really be a class that has an incoming frame slot and can connect to the canvas
[ ] tick() handler dependent controls
    [ ] let the filter set up controls it wants

football players tracking:

1. background learning
    - simplest: a movie of the empty field
        - not always possible
        - will change with time (sun, clouds)
    - statistical:
        - collect histograms of image tiles for some time
        - for each tile: find similar histograms that occur the oftenest, assume that to be the background
            - this requires automatic classification of the histograms
    - dynamic
        - start with initial background (e.g. all green, or a single shot of empty field or statistically collected)
        - after blob detection use remainder of the image to update the tile histograms
            - see codebooks (p. 278)
2. detect areas different from the background
    - given tile histogram generate backprojection
    - combine all tile's backprojections to a single probability image
    - threshold / morphological operations
3. find blob shapes
    - contours of "white" areas
4. calculate histograms inside the blobs
5. classify the blobs based on area / histogram
6. blob location
    - use mid-lowest point as blob coordinates (in case of a single player corresponds to feet at the ground level)
    - rectify / unproject based on 4 points

Extra considerations:
- cvPyrMeanShiftFiltering is slow but simplifies the image a lot. helps to keep the histograms distinct. when to use it? may be to generate the inital histograms.
- the furthest background (in the test video) can be problematic, but as long as their uniforms are bright and in contrast with the background it's ok
- it would be clever to perspective-correct image when scaling down: minimize amount of processing for the foreground and loss of detail for the background.
    - TODO find which opencv geometric transformation functions does it, there is one that can do both in one go.

Learning the field:
1. learning field color histogram
1.1. assume the field is green with white: have a default field histogram ready or let user rubber band a small portion to start it off
    (best a portion including light, shadow on both grass and white markings).
1.2. backproject the histogram onto the frame, collect pixels above sertain threshold into a field mask, calculate histogram of these pixels - this will be the new histogram
1.3. repeat increasing threshold until certain level of confidence / accuracy. Now we have the current field histogram
2. learning field position inside the frame
2.1. backproject field histogram onto current frame
2.2. do a morphological operation to fix small holes
2.3. select the largest contour and find its convex hull, around 6 corners. That's the field area
3. field shape fitting
3.1. divide the field into several roughly defined areas
3.2. search for features (corners of white marking) inside each area
3.3. each found corner corresponds to exact football (X,Y) -> use found corners to find tracking area, perspective correction and lens undistortion parameters


* * *

A flexible way to do video exploration:

[x] a VisionFilter registers a number of cv::Mat's in a dictionary
[x] it uses them directly because they are also its fields
[x] default 'incomingFrame()' does:
    1. store the incoming in the 'input' slot
    2. calls virtual filter() function
    3. displays selected slot

* * *

stagewise refactoring towards modular filter support:

[x] split current filter implementation into two classes - base filter class and football tracker
[x] split the face tracker part as well - including its gui
[x] remove the layer menu items
[x] remove the toolbar
[x] digit keys to stage selector: add key event handler to main window and react on digits there

* * *

[x] load the field-sample and take its histogram. this will be the starting field histogram
[-] backproject, threshold, update histogram (working field histogram)
[x] backproject, threshold, close, find blobs, take the largest, take its convex hull, this will be the field
    [ ] if several contours - keep the largest
    [ ] ROI - hull's bounding rect
    [ ] mask - draw hull as white

[ ] bg/fg segmentation: once we have an ROI and a mask do background detection, then inverse threshold and morph dilate
[ ] find all countours and show them as little blobular shapes

* * *

(Tue Mar 22)

switching to verilook again.

made a wizard for Mirror::VisionFilter subclasses.

